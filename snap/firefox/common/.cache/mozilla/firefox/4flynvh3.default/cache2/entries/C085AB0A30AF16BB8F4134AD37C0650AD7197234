{"meta":{"page":{"currentPage":1,"from":1,"lastPage":40,"perPage":4,"to":4,"total":160}},"jsonapi":{"version":"1.0"},"links":{"first":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications?filter%5Bpublished%5D=true&include=media&page%5Bnumber%5D=1&page%5Bsize%5D=4&sort=-publicationDate%2C-createdAt","last":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications?filter%5Bpublished%5D=true&include=media&page%5Bnumber%5D=40&page%5Bsize%5D=4&sort=-publicationDate%2C-createdAt","next":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications?filter%5Bpublished%5D=true&include=media&page%5Bnumber%5D=2&page%5Bsize%5D=4&sort=-publicationDate%2C-createdAt"},"data":[{"type":"research-publications","id":"208","attributes":{"published":true,"createdAt":"2023-03-20T16:29:02.000000Z","updatedAt":"2023-03-20T20:29:53.000000Z","publicationDateFormatted":"March 17, 2023","publicationDate":"2023-03-17T00:00:00-07:00","slug":"gpts-are-gpts","title":"GPTs are GPTs: An early look at the labor market impact potential of large language models","description":"","descriptionRichText":null,"heroBlendMode":"default","template":"level-0","colorTheme":null,"releaseSummary":null,"releaseWhyItMatters":null,"releaseSafety":null,"chapters":false,"publicationAbstract":"<p>We investigate the potential implications of Generative Pre-trained Transformer (GPT) models and related technologies on the U.S. labor market. Using a new rubric, we assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. Our findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. We conclude that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that as these models could have notable economic, social, and policy implications.<br class=\"softbreak\"><\/p>","publicationAbstractRichText":{"type":"div","props":[],"children":[{"type":"p","props":[],"children":["We investigate the potential implications of Generative Pre-trained Transformer (GPT) models and related technologies on the U.S. labor market. Using a new rubric, we assess occupations based on their correspondence with GPT capabilities, incorporating both human expertise and classifications from GPT-4. Our findings indicate that approximately 80% of the U.S. workforce could have at least 10% of their work tasks affected by the introduction of GPTs, while around 19% of workers may see at least 50% of their tasks impacted. The influence spans all wage levels, with higher-income jobs potentially facing greater exposure. Notably, the impact is not limited to industries with higher recent productivity growth. We conclude that Generative Pre-trained Transformers exhibit characteristics of general-purpose technologies (GPTs), suggesting that as these models could have notable economic, social, and policy implications.",{"type":"br","props":{"class":"softbreak"},"children":[]}]}]},"seo":{"ogImageSrc":"https:\/\/openaicom.imgix.net\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=%2C%2C%2C","ogImageAlt":"GPTs Are GPTs: An Early Look At The Labor Market Impact Potential Of Large Language Models","twitterImageSrc":null,"twitterImageAlt":null,"noindex":false,"description":"","ogTitle":"GPTs are GPTs: An early look at the labor market impact potential of large language models","ogDescription":"","twitterTitle":null,"twitterDescription":null,"twitterCardType":"summary_large_image"},"acknowledgments":{"title1":"Report authors","text1":"<p>Tyna Eloundou (OpenAI)<br class=\"softbreak\">Sam Manning (OpenAI, OpenResearch)<br class=\"softbreak\">Pamela Mishkin (OpenAI)<br class=\"softbreak\">Daniel Rock (University of Pennsylvania)<br class=\"softbreak\"><\/p>","title2":null,"text2":null}},"relationships":{"blocks":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/blocks","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/blocks"}},"media":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/media","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/media"},"data":[{"type":"media","id":"28134","meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}},{"type":"media","id":"28135","meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}},{"type":"media","id":"28136","meta":{"role":"cover","crop":"listing","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}}],"meta":{"roles":{"cover":{"+1 (No bleed)":["28134"],"+2 (Full bleed)":["28135"],"listing":["28136"]}}}},"files":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/files","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/files"}},"related-items":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/related-items","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/related-items"}},"ctas":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/ctas","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/ctas"}},"research-publication-links":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/research-publication-links","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/research-publication-links"}},"author-groups":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/author-groups","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/author-groups"}},"topics":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/topics","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/topics"}},"models":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/models","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/models"}},"content-types":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/content-types","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/content-types"}},"footnotes":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/footnotes","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/footnotes"}},"references":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/references","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208\/relationships\/references"}}},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/208"}},{"type":"research-publications","id":"189","attributes":{"published":true,"createdAt":"2023-03-13T03:16:55.000000Z","updatedAt":"2023-03-16T04:56:57.000000Z","publicationDateFormatted":"March 14, 2023","publicationDate":"2023-03-14T00:00:00-07:00","slug":"gpt-4","title":"GPT-4","description":"We\u2019ve created GPT-4, the latest milestone in OpenAI\u2019s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.","descriptionRichText":{"type":"div","props":[],"children":[{"type":"p","props":[],"children":["We\u2019ve created GPT-4, the latest milestone in OpenAI\u2019s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.",{"type":"br","props":{"class":"softbreak"},"children":[]}]}]},"heroBlendMode":"default","template":"level-1","colorTheme":"mid-green","releaseSummary":null,"releaseWhyItMatters":null,"releaseSafety":null,"chapters":false,"publicationAbstract":null,"publicationAbstractRichText":null,"seo":{"ogImageSrc":"https:\/\/openaicom.imgix.net\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C681%2C2048%2C1367","ogImageAlt":"GPT-4","twitterImageSrc":null,"twitterImageAlt":null,"noindex":false,"description":"We\u2019ve created GPT-4, the latest milestone in OpenAI\u2019s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.","ogTitle":"GPT-4","ogDescription":"We\u2019ve created GPT-4, the latest milestone in OpenAI\u2019s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks.","twitterTitle":null,"twitterDescription":null,"twitterCardType":"summary_large_image"},"acknowledgments":{"title1":null,"text1":"<p><a href=\"\/contributions\/gpt-4\" rel=\"noopener noreferrer\">View GPT-4 contributions<\/a><br class=\"softbreak\"><\/p>","title2":null,"text2":null}},"relationships":{"blocks":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/blocks","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/blocks"}},"media":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/media","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/media"},"data":[{"type":"media","id":"29561","meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}},{"type":"media","id":"29562","meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}},{"type":"media","id":"29563","meta":{"role":"cover","crop":"listing","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}}],"meta":{"roles":{"cover":{"+1 (No bleed)":["29561"],"+2 (Full bleed)":["29562"],"listing":["29563"]}}}},"files":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/files","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/files"}},"related-items":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/related-items","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/related-items"}},"ctas":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/ctas","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/ctas"}},"research-publication-links":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/research-publication-links","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/research-publication-links"}},"author-groups":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/author-groups","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/author-groups"}},"topics":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/topics","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/topics"}},"models":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/models","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/models"}},"content-types":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/content-types","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/content-types"}},"footnotes":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/footnotes","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/footnotes"}},"references":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/references","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189\/relationships\/references"}}},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/189"}},{"type":"research-publications","id":"162","attributes":{"published":true,"createdAt":"2023-01-17T21:50:41.000000Z","updatedAt":"2023-02-10T13:18:29.000000Z","publicationDateFormatted":"January 11, 2023","publicationDate":"2023-01-11T00:00:00-08:00","slug":"forecasting-misuse","title":"Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk","description":"OpenAI researchers collaborated with Georgetown University\u2019s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report\u00a0here.","descriptionRichText":{"type":"div","props":[],"children":[{"type":"p","props":[],"children":["OpenAI researchers collaborated with Georgetown University\u2019s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report\u00a0",{"type":"a","props":{"href":"https:\/\/arxiv.org\/abs\/2301.04246","rel":"noopener noreferrer","target":"_blank"},"children":["here"]},".",{"type":"br","props":{"class":"softbreak"},"children":[]}]}]},"heroBlendMode":"default","template":"level-1","colorTheme":"mid-brown","releaseSummary":null,"releaseWhyItMatters":null,"releaseSafety":null,"chapters":false,"publicationAbstract":null,"publicationAbstractRichText":null,"seo":{"ogImageSrc":"https:\/\/openaicom.imgix.net\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2304%2C2304","ogImageAlt":"Forecasting Misuse","twitterImageSrc":null,"twitterImageAlt":null,"noindex":false,"description":"OpenAI researchers collaborated with Georgetown University\u2019s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report\u00a0here.","ogTitle":"Forecasting potential misuses of language models for disinformation campaigns and how to reduce risk","ogDescription":"OpenAI researchers collaborated with Georgetown University\u2019s Center for Security and Emerging Technology and the Stanford Internet Observatory to investigate how large language models might be misused for disinformation purposes. The collaboration included an October 2021 workshop bringing together 30 disinformation researchers, machine learning experts, and policy analysts, and culminated in a co-authored report building on more than a year of research. This report outlines the threats that language models pose to the information environment if used to augment disinformation campaigns and introduces a framework for analyzing potential mitigations. Read the full report\u00a0here.","twitterTitle":null,"twitterDescription":null,"twitterCardType":"summary_large_image"},"acknowledgments":{"title1":"Report authors","text1":"<p>Josh A. Goldstein (Georgetown University\u2019s Center for Security and Emerging Technology)<br class=\"softbreak\">Girish Sastry (OpenAI)<br class=\"softbreak\">Micah Musser (Center for Security and Emerging Technology)<br class=\"softbreak\">Ren\u00e9e DiResta (Stanford Internet Observatory)<br class=\"softbreak\">Matthew Gentzel (Longview Philanthropy) (work done at OpenAI)<br class=\"softbreak\">Katerina Sedova (US Department of State) (work done at Center for Security and Emerging Technology prior to government&nbsp;service)<br class=\"softbreak\"><\/p>","title2":null,"text2":null}},"relationships":{"blocks":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/blocks","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/blocks"}},"media":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/media","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/media"},"data":[{"type":"media","id":"29564","meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}},{"type":"media","id":"29565","meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}},{"type":"media","id":"29566","meta":{"role":"cover","crop":"listing","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}}],"meta":{"roles":{"cover":{"+1 (No bleed)":["29564"],"+2 (Full bleed)":["29565"],"listing":["29566"]}}}},"files":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/files","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/files"}},"related-items":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/related-items","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/related-items"}},"ctas":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/ctas","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/ctas"}},"research-publication-links":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/research-publication-links","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/research-publication-links"}},"author-groups":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/author-groups","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/author-groups"}},"topics":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/topics","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/topics"}},"models":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/models","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/models"}},"content-types":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/content-types","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/content-types"}},"footnotes":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/footnotes","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/footnotes"}},"references":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/references","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162\/relationships\/references"}}},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/162"}},{"type":"research-publications","id":"106","attributes":{"published":true,"createdAt":"2023-01-09T15:56:07.000000Z","updatedAt":"2023-01-24T22:17:54.000000Z","publicationDateFormatted":"December 16, 2022","publicationDate":"2022-12-16T00:00:00-08:00","slug":"point-e","title":"Point-E: A system for generating 3D point clouds from complex prompts","description":"","descriptionRichText":null,"heroBlendMode":"default","template":"level-0","colorTheme":null,"releaseSummary":null,"releaseWhyItMatters":null,"releaseSafety":null,"chapters":false,"publicationAbstract":"<p>While recent work on text-conditional 3D object generation has shown promising results, the state-of-the-art methods typically require multiple GPU-hours to produce a single sample. This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes. In this paper, we explore an alternative method for 3D object generation which produces 3D models in only 1-2 minutes on a single GPU. Our method first generates a single synthetic view using a text-to-image diffusion model, and then produces a 3D point cloud using a second diffusion model which conditions on the generated image. While our method still falls short of the state-of-the-art in terms of sample quality, it is one to two orders of magnitude faster to sample from, offering a practical trade-off for some use cases. We release our pre-trained point cloud diffusion models, as well as evaluation code and models, at&nbsp;<a href=\"https:\/\/github.com\/openai\/point-e\" rel=\"noopener noreferrer\" target=\"_blank\">this https URL<\/a>.<br class=\"softbreak\"><\/p>","publicationAbstractRichText":{"type":"div","props":[],"children":[{"type":"p","props":[],"children":["While recent work on text-conditional 3D object generation has shown promising results, the state-of-the-art methods typically require multiple GPU-hours to produce a single sample. This is in stark contrast to state-of-the-art generative image models, which produce samples in a number of seconds or minutes. In this paper, we explore an alternative method for 3D object generation which produces 3D models in only 1-2 minutes on a single GPU. Our method first generates a single synthetic view using a text-to-image diffusion model, and then produces a 3D point cloud using a second diffusion model which conditions on the generated image. While our method still falls short of the state-of-the-art in terms of sample quality, it is one to two orders of magnitude faster to sample from, offering a practical trade-off for some use cases. We release our pre-trained point cloud diffusion models, as well as evaluation code and models, at\u00a0",{"type":"a","props":{"href":"https:\/\/github.com\/openai\/point-e","rel":"noopener noreferrer","target":"_blank"},"children":["this https URL"]},".",{"type":"br","props":{"class":"softbreak"},"children":[]}]}]},"seo":{"ogImageSrc":"https:\/\/openaicom.imgix.net\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2064%2C2064","ogImageAlt":"Point E A System For Generating 3d Point Clouds From Complex Prompts","twitterImageSrc":null,"twitterImageAlt":null,"noindex":false,"description":"","ogTitle":"Point-E: A system for generating 3D point clouds from complex prompts","ogDescription":"","twitterTitle":null,"twitterDescription":null,"twitterCardType":"summary_large_image"},"acknowledgments":{"title1":null,"text1":null,"title2":null,"text2":null}},"relationships":{"blocks":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/blocks","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/blocks"}},"media":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/media","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/media"},"data":[{"type":"media","id":"7861","meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}},{"type":"media","id":"7862","meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}},{"type":"media","id":"7863","meta":{"role":"cover","crop":"listing","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}}],"meta":{"roles":{"cover":{"+1 (No bleed)":["7861"],"+2 (Full bleed)":["7862"],"listing":["7863"]}}}},"files":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/files","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/files"}},"related-items":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/related-items","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/related-items"}},"ctas":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/ctas","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/ctas"}},"research-publication-links":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/research-publication-links","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/research-publication-links"}},"author-groups":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/author-groups","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/author-groups"}},"topics":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/topics","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/topics"}},"models":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/models","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/models"}},"content-types":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/content-types","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/content-types"}},"footnotes":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/footnotes","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/footnotes"}},"references":{"links":{"related":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/references","self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106\/relationships\/references"}}},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/research-publications\/106"}}],"included":[{"type":"media","id":"28134","attributes":{"createdAt":"2023-03-20T20:29:53.000000Z","updatedAt":"2023-03-20T20:29:53.000000Z","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","filename":"gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","role":"cover","crop":"+1 (No bleed)","ratio":"1:1","lqip":null,"src":"https:\/\/openaicom.imgix.net\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=%2C%2C%2C","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","width":2064,"height":2064,"alt":"GPTs Are GPTs: An Early Look At The Labor Market Impact Potential Of Large Language Models","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/28134"},"meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}},{"type":"media","id":"28135","attributes":{"createdAt":"2023-03-20T20:29:53.000000Z","updatedAt":"2023-03-20T20:29:53.000000Z","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","filename":"gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","role":"cover","crop":"+2 (Full bleed)","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=%2C%2C%2C","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","width":2064,"height":2064,"alt":"GPTs Are GPTs: An Early Look At The Labor Market Impact Potential Of Large Language Models","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/28135"},"meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}},{"type":"media","id":"28136","attributes":{"createdAt":"2023-03-20T20:29:53.000000Z","updatedAt":"2023-03-20T20:29:53.000000Z","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","filename":"gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","role":"cover","crop":"listing","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=%2C%2C%2C","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png","width":2064,"height":2064,"alt":"GPTs Are GPTs: An Early Look At The Labor Market Impact Potential Of Large Language Models","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/28136"},"meta":{"role":"cover","crop":"listing","uuid":"b5b6da55-f60d-43b3-a40f-902b9baf57e0\/gpts-are-gpts-an-early-look-at-the-labor-market-impact-potential-of-large-language-models.png"}},{"type":"media","id":"29561","attributes":{"createdAt":"2023-04-05T16:22:25.000000Z","updatedAt":"2023-04-05T16:22:25.000000Z","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","filename":"gpt-4.png","role":"cover","crop":"+1 (No bleed)","ratio":"3:2","lqip":null,"src":"https:\/\/openaicom.imgix.net\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C681%2C2048%2C1367","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","width":2048,"height":1367,"alt":"GPT-4","caption":"<p>Illustration:&nbsp;Ruby Chen<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29561"},"meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}},{"type":"media","id":"29562","attributes":{"createdAt":"2023-04-05T16:22:25.000000Z","updatedAt":"2023-04-05T16:22:25.000000Z","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","filename":"gpt-4.png","role":"cover","crop":"+2 (Full bleed)","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2048%2C2048","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","width":2048,"height":2048,"alt":"GPT-4","caption":"<p>Illustration:&nbsp;Ruby Chen<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29562"},"meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}},{"type":"media","id":"29563","attributes":{"createdAt":"2023-04-05T16:22:25.000000Z","updatedAt":"2023-04-05T16:22:25.000000Z","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","filename":"gpt-4.png","role":"cover","crop":"listing","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2048%2C2048","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png","width":2048,"height":2048,"alt":"GPT-4","caption":"<p>Illustration:&nbsp;Ruby Chen<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29563"},"meta":{"role":"cover","crop":"listing","uuid":"243b509f-9d19-438e-a2ce-05e9ea5086a9\/gpt-4.png"}},{"type":"media","id":"29564","attributes":{"createdAt":"2023-04-05T16:24:18.000000Z","updatedAt":"2023-04-05T16:24:18.000000Z","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","filename":"forecasting-misuse.png","role":"cover","crop":"+1 (No bleed)","ratio":"1:1","lqip":null,"src":"https:\/\/openaicom.imgix.net\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2304%2C2304","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","width":2304,"height":2304,"alt":"Forecasting Misuse","caption":"<p>Illustration:&nbsp;Justin Jay Wang<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29564"},"meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}},{"type":"media","id":"29565","attributes":{"createdAt":"2023-04-05T16:24:18.000000Z","updatedAt":"2023-04-05T16:24:18.000000Z","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","filename":"forecasting-misuse.png","role":"cover","crop":"+2 (Full bleed)","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2304%2C2304","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","width":2304,"height":2304,"alt":"Forecasting Misuse","caption":"<p>Illustration:&nbsp;Justin Jay Wang<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29565"},"meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}},{"type":"media","id":"29566","attributes":{"createdAt":"2023-04-05T16:24:18.000000Z","updatedAt":"2023-04-05T16:24:18.000000Z","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","filename":"forecasting-misuse.png","role":"cover","crop":"listing","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2304%2C2304","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png","width":2304,"height":2304,"alt":"Forecasting Misuse","caption":"<p>Illustration:&nbsp;Justin Jay Wang<br class=\"softbreak\"><\/p>","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/29566"},"meta":{"role":"cover","crop":"listing","uuid":"2e288b87-2d80-4fa6-abea-5d9e650d7143\/forecasting-misuse.png"}},{"type":"media","id":"7861","attributes":{"createdAt":"2023-01-24T23:38:23.000000Z","updatedAt":"2023-01-24T23:38:23.000000Z","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","filename":"point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","role":"cover","crop":"+1 (No bleed)","ratio":"1:1","lqip":null,"src":"https:\/\/openaicom.imgix.net\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2064%2C2064","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","width":2064,"height":2064,"alt":"Point E A System For Generating 3d Point Clouds From Complex Prompts","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/7861"},"meta":{"role":"cover","crop":"+1 (No bleed)","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}},{"type":"media","id":"7862","attributes":{"createdAt":"2023-01-24T23:38:23.000000Z","updatedAt":"2023-01-24T23:38:23.000000Z","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","filename":"point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","role":"cover","crop":"+2 (Full bleed)","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2064%2C2064","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","width":2064,"height":2064,"alt":"Point E A System For Generating 3d Point Clouds From Complex Prompts","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/7862"},"meta":{"role":"cover","crop":"+2 (Full bleed)","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}},{"type":"media","id":"7863","attributes":{"createdAt":"2023-01-24T23:38:23.000000Z","updatedAt":"2023-01-24T23:38:23.000000Z","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","filename":"point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","role":"cover","crop":"listing","ratio":"default","lqip":null,"src":"https:\/\/openaicom.imgix.net\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2064%2C2064","originalSrc":"https:\/\/openaicomproductionae4b.blob.core.windows.net\/production-twill-01\/7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png","width":2064,"height":2064,"alt":"Point E A System For Generating 3d Point Clouds From Complex Prompts","caption":"","video":"","metadata":[]},"links":{"self":"https:\/\/openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net\/api\/v1\/media\/7863"},"meta":{"role":"cover","crop":"listing","uuid":"7e4ba260-7655-4049-90a2-d4eb5bef3c5c\/point-e-a-system-for-generating-3d-point-clouds-from-complex-prompts.png"}}]}˛Ê1(*V      d=çd=çE{;J       €    O^partitionKey=%28https%2Copenai.com%29,a,:https://openaicom-api-bdcpf8c6d2e9atf6.z01.azurefd.net/api/v1/research-publications?sort=-publicationDate%2C-createdAt&page%5Bsize%5D=4&include=media&filter%5Bpublished%5D=true necko:classified 1 strongly-framed 1 security-info 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 request-method GET response-head HTTP/2 200 OK
date: Mon, 17 Apr 2023 18:16:35 GMT
content-type: application/vnd.api+json
cache-control: no-cache
content-language: en
access-control-allow-origin: *
x-frame-options: SAMEORIGIN
x-xss-protection: 1; mode=block
x-content-type-options: nosniff
x-azure-ref: 20230417T181635Z-v9838rwwd53rxcqbduxt62ybbc00000005n00000000299c3
x-cache: TCP_MISS
X-Firefox-Spdy: h2
 original-response-headers date: Mon, 17 Apr 2023 18:16:35 GMT
content-type: application/vnd.api+json
cache-control: no-cache
content-language: en
access-control-allow-origin: *
x-frame-options: SAMEORIGIN
x-xss-protection: 1; mode=block
x-content-type-options: nosniff
x-azure-ref: 20230417T181635Z-v9838rwwd53rxcqbduxt62ybbc00000005n00000000299c3
x-cache: TCP_MISS
X-Firefox-Spdy: h2
 ctid 1 net-response-time-onstart 602 net-response-time-onstop 1239   Øµ